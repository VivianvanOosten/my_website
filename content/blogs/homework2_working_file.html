---
title: "Session 4: Homework 2"
author: "Group 12: Samarth Sharma, Vivian van Oosten, Anastasia Fu, Jaelyn Shi, Andrew Robak, Shivant Maharaj"
date: "2022-09-14"
output:
  html_document:
    theme: flatly
    highlight: zenburn
    number_sections: yes
    toc: yes
    toc_float: yes
    code_folding: show
editor_options: 
  markdown: 
    wrap: 72
---



<div id="climate-change-and-temperature-anomalies" class="section level1">
<h1>Climate change and temperature anomalies</h1>
<p>We are analysing a dataset from NASA’s Goddard Institute for Space
Studies to study the effects of climate change in the Northern
Hemisphere. Glimpsing at the data, we see there are 19 variables and 143
observations, representing the period between 1880-2022:</p>
<pre class="r"><code>weather &lt;- 
  read_csv(&quot;https://data.giss.nasa.gov/gistemp/tabledata_v4/NH.Ts+dSST.csv&quot;, 
           skip = 1, 
           na = &quot;***&quot;)
glimpse(weather)</code></pre>
<pre><code>## Rows: 143
## Columns: 19
## $ Year  &lt;dbl&gt; 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890…
## $ Jan   &lt;dbl&gt; -0.39, -0.30, 0.26, -0.58, -0.16, -1.01, -0.75, -1.08, -0.49, -0…
## $ Feb   &lt;dbl&gt; -0.53, -0.24, 0.21, -0.66, -0.11, -0.45, -0.84, -0.71, -0.61, 0.…
## $ Mar   &lt;dbl&gt; -0.23, -0.05, 0.02, -0.15, -0.64, -0.23, -0.71, -0.44, -0.64, -0…
## $ Apr   &lt;dbl&gt; -0.30, -0.02, -0.30, -0.30, -0.59, -0.49, -0.37, -0.38, -0.22, 0…
## $ May   &lt;dbl&gt; -0.05, 0.05, -0.23, -0.25, -0.36, -0.58, -0.34, -0.25, -0.15, -0…
## $ Jun   &lt;dbl&gt; -0.18, -0.33, -0.28, -0.11, -0.41, -0.45, -0.37, -0.20, -0.03, -…
## $ Jul   &lt;dbl&gt; -0.21, 0.10, -0.28, -0.05, -0.41, -0.34, -0.14, -0.24, 0.00, -0.…
## $ Aug   &lt;dbl&gt; -0.25, -0.04, -0.14, -0.22, -0.51, -0.41, -0.43, -0.54, -0.21, -…
## $ Sep   &lt;dbl&gt; -0.24, -0.28, -0.24, -0.34, -0.45, -0.40, -0.33, -0.21, -0.20, -…
## $ Oct   &lt;dbl&gt; -0.30, -0.44, -0.51, -0.16, -0.44, -0.37, -0.31, -0.49, -0.03, -…
## $ Nov   &lt;dbl&gt; -0.43, -0.36, -0.33, -0.44, -0.57, -0.38, -0.40, -0.27, -0.01, -…
## $ Dec   &lt;dbl&gt; -0.42, -0.23, -0.68, -0.15, -0.47, -0.11, -0.22, -0.43, -0.24, -…
## $ `J-D` &lt;dbl&gt; -0.29, -0.18, -0.21, -0.29, -0.43, -0.43, -0.43, -0.44, -0.24, -…
## $ `D-N` &lt;dbl&gt; NA, -0.19, -0.17, -0.33, -0.40, -0.46, -0.42, -0.42, -0.25, -0.1…
## $ DJF   &lt;dbl&gt; NA, -0.32, 0.08, -0.64, -0.14, -0.64, -0.57, -0.67, -0.51, -0.08…
## $ MAM   &lt;dbl&gt; -0.19, -0.01, -0.17, -0.24, -0.53, -0.43, -0.47, -0.36, -0.33, 0…
## $ JJA   &lt;dbl&gt; -0.21, -0.09, -0.23, -0.13, -0.44, -0.40, -0.31, -0.33, -0.08, -…
## $ SON   &lt;dbl&gt; -0.32, -0.36, -0.36, -0.31, -0.49, -0.38, -0.35, -0.32, -0.08, -…</code></pre>
<p>For the purpose of our analysis, we have decided to select only data
pertaining to temperature deviation (delta) by month, and manipulate the
dataframe to facilitate further investigation:</p>
<pre class="r"><code>tidyweather &lt;- select(weather, 1:13) %&gt;% 
  pivot_longer(!Year, names_to = &#39;month&#39;, values_to = &#39;delta&#39;)
head(tidyweather)</code></pre>
<pre><code>## # A tibble: 6 × 3
##    Year month delta
##   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;
## 1  1880 Jan   -0.39
## 2  1880 Feb   -0.53
## 3  1880 Mar   -0.23
## 4  1880 Apr   -0.3 
## 5  1880 May   -0.05
## 6  1880 Jun   -0.18</code></pre>
<div id="plotting-information" class="section level2">
<h2>Plotting Information</h2>
<p>First, we are plotting a scatter plot to visualize the evolution of
delta (temperature deviation) over time:</p>
<pre class="r"><code>tidyweather &lt;- tidyweather %&gt;%
  mutate(date = ymd(paste(as.character(Year), month, &quot;1&quot;)),
         month = month(date, label=TRUE),
         year = year(date))

ggplot(tidyweather, aes(x=date, y = delta))+
  geom_point()+
  geom_smooth(color=&quot;red&quot;) +
  theme_bw() +
  labs (
    title = &quot;Weather Anomalies&quot;
  )</code></pre>
<p><img src="/blogs/homework2_working_file_files/figure-html/scatter_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>Adding a line of best fit to the scatterplot clearly shows that, while
deltas were close to 0 between approximately 1935-1975 and negative
before that time, temperature in the Northern Hempishere has been
quickly increasing since then. Notice that the rate of the increase has
been increasing as well (as signified by increasing deltas).</p>
<p>Next, we will use <code>facet_wrap()</code> to visualize the effects of increasing
temperature by month:</p>
<p><img src="/blogs/homework2_working_file_files/figure-html/facet_wrap-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>We can see that the effect of rising temperature in the Northern
Hemisphere is common to all months of the year.</p>
<p>As a means to further investigate the effects of climate change, we will
partition the data into time periods, particularly decades. To that end,
we will use <code>case_when()</code>:</p>
<pre class="r"><code>comparison &lt;- tidyweather %&gt;% 
  filter(Year&gt;= 1881) %&gt;%     #remove years prior to 1881
  #create new variable &#39;interval&#39;, and assign values based on criteria below:
  mutate(interval = case_when(
    Year %in% c(1881:1920) ~ &quot;1881-1920&quot;,
    Year %in% c(1921:1950) ~ &quot;1921-1950&quot;,
    Year %in% c(1951:1980) ~ &quot;1951-1980&quot;,
    Year %in% c(1981:2010) ~ &quot;1981-2010&quot;,
    TRUE ~ &quot;2011-present&quot;
  ))</code></pre>
<p>In order to study the effects of climate change by decade, we will
produce a density plot to investigate the distribution of monthly
temperature deviations by the time periods selected above:</p>
<pre class="r"><code>ggplot(comparison) +
  aes(x = delta, fill = interval)+
  #facet_wrap(~month)+
  geom_density(alpha = 0.2) </code></pre>
<p><img src="/blogs/homework2_working_file_files/figure-html/density_plot-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>The plot clearly shows that with the passage of time, deltas have
consistently moved to the right hand side of the plot. In other words,
temperature deviations have been increasing over time.</p>
<p>Lastly, we will also consider annual anomalies by grouping the monthly
data and producing a scatterplot:</p>
<pre class="r"><code>#creating yearly averages
average_annual_anomaly &lt;- tidyweather %&gt;% 
  group_by(Year) %&gt;%   #grouping data by Year
  
  # creating summaries for mean delta 
  # use `na.rm=TRUE` to eliminate NA (not available) values 
  summarise(yearly_mean = mean(delta, na.rm=TRUE)) 
  
average_annual_anomaly</code></pre>
<pre><code>## # A tibble: 143 × 2
##     Year yearly_mean
##    &lt;dbl&gt;       &lt;dbl&gt;
##  1  1880      -0.294
##  2  1881      -0.178
##  3  1882      -0.208
##  4  1883      -0.284
##  5  1884      -0.427
##  6  1885      -0.435
##  7  1886      -0.434
##  8  1887      -0.437
##  9  1888      -0.236
## 10  1889      -0.177
## # … with 133 more rows</code></pre>
<pre class="r"><code>#plotting the data
#Fit the best fit line, using LOESS method
ggplot(average_annual_anomaly) +
  aes(x = Year, y = yearly_mean)+
  geom_point()+
  geom_smooth(method = &#39;lm&#39;) +
  theme_bw()</code></pre>
<p><img src="/blogs/homework2_working_file_files/figure-html/averaging-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>The plot proves that annual temprature deltas have been increasing over
time.</p>
</div>
<div id="confidence-interval-for-delta" class="section level2">
<h2>Confidence Interval for <code>delta</code></h2>
<p>We will now focus on the time period between 2011-present. We divert our
attention towards producing a confidence interval for the average annual
deltas calculated since 2011. We will use both the statistical method
and bootstrap simulation to have more confidence in the results:</p>
<pre class="r"><code>#statistical method
formula_ci &lt;- comparison %&gt;% 
  filter(interval == &#39;2011-present&#39;) %&gt;% 
  group_by(year) %&gt;% 
  summarise(avg_annual_delta = mean(delta),
            sd_delta = sd(delta),
            count = n(),
            SE = sd(delta/sqrt(count)),
            upper_ci = avg_annual_delta + 2*SE,
            lower_ci = avg_annual_delta - 2*SE)

#bootstrap simulation  
formula_ci_2 &lt;- comparison %&gt;% 
  filter(interval == &#39;2011-present&#39;) %&gt;% 
  specify(response = delta) %&gt;% 
  generate(type = &#39;bootstrap&#39;) %&gt;% 
  calculate(stat = &#39;mean&#39;) %&gt;% 
  get_confidence_interval(level = 0.95)

#print out formula_CI
formula_ci</code></pre>
<pre><code>## # A tibble: 12 × 7
##     year avg_annual_delta sd_delta count      SE upper_ci lower_ci
##    &lt;dbl&gt;            &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
##  1  2011            0.745    0.113    12  0.0327    0.810    0.680
##  2  2012            0.815    0.179    12  0.0517    0.918    0.712
##  3  2013            0.8      0.118    12  0.0340    0.868    0.732
##  4  2014            0.92     0.145    12  0.0420    1.00     0.836
##  5  2015            1.18     0.178    12  0.0515    1.28     1.07 
##  6  2016            1.31     0.333    12  0.0961    1.50     1.12 
##  7  2017            1.18     0.226    12  0.0653    1.31     1.05 
##  8  2018            1.04     0.137    12  0.0396    1.12     0.957
##  9  2019            1.21     0.153    12  0.0441    1.30     1.12 
## 10  2020            1.35     0.225    12  0.0648    1.48     1.22 
## 11  2021            1.14     0.117    12  0.0339    1.20     1.07 
## 12  2022           NA       NA        12 NA        NA       NA</code></pre>
<pre class="r"><code>formula_ci_2</code></pre>
<pre><code>## # A tibble: 1 × 2
##   lower_ci upper_ci
##      &lt;dbl&gt;    &lt;dbl&gt;
## 1     1.06     1.06</code></pre>
<p>Looking at the results of the analysis, we can see that the statistical
method produces wider confidence intervals for temperature deltas,
ranging from 0.13 to approximately 0.3 in width. This is probably due to
the low number of observations (12 months in each year), which prohibit
a more precise calculation. On the other hand, using bootstrap
simulation allows to get a much narrower confidence interval. However,
both methods show that temperature deltas have been positive in the time
period in question and have been consistently greater than 1 since 2015.</p>
</div>
</div>
<div id="bidens-approval-margins" class="section level1">
<h1>Biden’s Approval Margins</h1>
<p>In this section, we will analyse the evolution of approval margins of US
President Joe Biden. Glimpsing at the dataset, we notice there are 22
variables and 4,495 observations:</p>
<pre class="r"><code># Import approval polls data directly off fivethirtyeight website
approval_polllist &lt;- read_csv(&#39;https://projects.fivethirtyeight.com/biden-approval-data/approval_polllist.csv&#39;) 

glimpse(approval_polllist)</code></pre>
<pre><code>## Rows: 4,537
## Columns: 22
## $ president           &lt;chr&gt; &quot;Joe Biden&quot;, &quot;Joe Biden&quot;, &quot;Joe Biden&quot;, &quot;Joe Biden&quot;…
## $ subgroup            &lt;chr&gt; &quot;All polls&quot;, &quot;All polls&quot;, &quot;All polls&quot;, &quot;All polls&quot;…
## $ modeldate           &lt;chr&gt; &quot;9/14/2022&quot;, &quot;9/14/2022&quot;, &quot;9/14/2022&quot;, &quot;9/14/2022&quot;…
## $ startdate           &lt;chr&gt; &quot;1/19/2021&quot;, &quot;1/19/2021&quot;, &quot;1/20/2021&quot;, &quot;1/20/2021&quot;…
## $ enddate             &lt;chr&gt; &quot;1/21/2021&quot;, &quot;1/21/2021&quot;, &quot;1/22/2021&quot;, &quot;1/21/2021&quot;…
## $ pollster            &lt;chr&gt; &quot;Rasmussen Reports/Pulse Opinion Research&quot;, &quot;Morni…
## $ grade               &lt;chr&gt; &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B-&quot;, &quot;B+&quot;, &quot;B-&quot;, &quot;B&quot;, &quot;B+&quot;, &quot;…
## $ samplesize          &lt;dbl&gt; 1500, 15000, 15000, 1993, 1115, 1516, 1200, 15000,…
## $ population          &lt;chr&gt; &quot;lv&quot;, &quot;a&quot;, &quot;a&quot;, &quot;rv&quot;, &quot;a&quot;, &quot;a&quot;, &quot;rv&quot;, &quot;a&quot;, &quot;rv&quot;, &quot;…
## $ weight              &lt;dbl&gt; 0.3382, 0.2594, 0.2333, 0.0930, 1.1014, 1.2454, 0.…
## $ influence           &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
## $ approve             &lt;dbl&gt; 48.0, 50.0, 51.0, 56.0, 55.5, 45.0, 58.0, 52.0, 63…
## $ disapprove          &lt;dbl&gt; 45.0, 28.0, 28.0, 31.0, 31.6, 28.0, 32.0, 29.0, 37…
## $ adjusted_approve    &lt;dbl&gt; 49.1, 49.4, 50.4, 55.4, 54.6, 46.0, 57.5, 51.4, 59…
## $ adjusted_disapprove &lt;dbl&gt; 40.3, 30.9, 30.9, 33.9, 32.4, 29.0, 32.8, 31.9, 38…
## $ multiversions       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…
## $ tracking            &lt;lgl&gt; TRUE, TRUE, TRUE, NA, NA, NA, NA, TRUE, NA, TRUE, …
## $ url                 &lt;chr&gt; &quot;https://www.rasmussenreports.com/public_content/p…
## $ poll_id             &lt;dbl&gt; 74247, 74272, 74273, 74246, 74248, 74327, 74270, 7…
## $ question_id         &lt;dbl&gt; 139395, 139491, 139492, 139394, 139404, 139570, 13…
## $ createddate         &lt;chr&gt; &quot;1/22/2021&quot;, &quot;1/28/2021&quot;, &quot;1/28/2021&quot;, &quot;1/22/2021&quot;…
## $ timestamp           &lt;chr&gt; &quot;11:13:31 14 Sep 2022&quot;, &quot;11:13:31 14 Sep 2022&quot;, &quot;1…</code></pre>
<div id="create-a-plot" class="section level2">
<h2>Create a plot</h2>
<p>We will first calculate the net approval rate (approve - disapprove) for
each week in 2022 along with its 95% confidence interval, and then plot
the results as a line plot grouping by respondent group (Adults, Voters,
All Groups).</p>
<pre class="r"><code>fixed_dates &lt;- approval_polllist %&gt;%
  mutate(date = mdy(enddate),
         weeks = week(date),
         year = year(date),
         net_rate = approve - disapprove) %&gt;%
  filter(year == 2022, weeks&lt;50) %&gt;%
  group_by(subgroup , weeks) %&gt;%
  
  # we calculated the 95% confidence interval. 
  summarise(mean_rate = mean(net_rate,na.rm=TRUE),
            sd_rate = sd(net_rate,na.rm=TRUE),
            number = n(),
            t_critical = qt(0.975,number-1),
            lower_bound = mean_rate - t_critical*sd_rate/ sqrt(number),
            upper_bound = mean_rate + t_critical*sd_rate/ sqrt(number)) 

# we draw the graph of the net approval rate changing over weeks with its confidence interval.
  ggplot(fixed_dates, aes(x = weeks, y = mean_rate, color = subgroup)) + 
  geom_ribbon(aes(ymin = lower_bound, ymax = upper_bound), 
              fill = &quot;orange&quot;, 
              alpha = 0.25, 
              show.legend = FALSE) +
    facet_grid(rows = vars(subgroup)) +
    geom_line(aes(x = weeks, y = mean_rate, 
                  color = subgroup),
              show.legend = FALSE) +
    labs(title = &quot;Biden&#39;s net approval ratings in 2022&quot;,
         subtitle = &quot;Weekly Data, Approve - Disapprove, %&quot;,
         caption = &quot;Source: https://projects.fivethirtyeight.com/biden-approval-data/&quot;,
         x = NULL, 
         y = NULL) +
    theme_minimal()</code></pre>
<p><img src="/blogs/homework2_working_file_files/figure-html/question2-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>We can see President Biden’s net approval relative has remained negative
since the first week of 2022 among all poll respondents, meaning more
people disapprove than approve of the President. Furthermore, we notice
a sharp decline in the net approval rate beginning in week 23. Since
that time, the approval rate seems to have returned to pre-drop levels,
potentially due to the POTUS’s recent delivery on several campaign
promises, primarily passing the Inflation Reduction Act.</p>
</div>
</div>
<div id="challenge-1-excess-rentals-in-tfl-bike-sharing" class="section level1">
<h1>Challenge 1: Excess rentals in TfL bike sharing</h1>
<p>This section focuses on analysing data on rentals in Tfl bike sharing.</p>
<pre class="r"><code>url &lt;- &quot;https://data.london.gov.uk/download/number-bicycle-hires/ac29363e-e0cb-47cc-a97a-e216d900a6b0/tfl-daily-cycle-hires.xlsx&quot;

# Download TFL data to temporary file
httr::GET(url, write_disk(bike.temp &lt;- tempfile(fileext = &quot;.xlsx&quot;)))</code></pre>
<pre><code>## Response [https://airdrive-secure.s3-eu-west-1.amazonaws.com/london/dataset/number-bicycle-hires/2022-09-06T12%3A41%3A48/tfl-daily-cycle-hires.xlsx?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAJJDIMAIVZJDICKHA%2F20220914%2Feu-west-1%2Fs3%2Faws4_request&amp;X-Amz-Date=20220914T173703Z&amp;X-Amz-Expires=300&amp;X-Amz-Signature=871bd79e57eb52e03d9c44c32a26d52808a9c12555836b5b986b9918d146740e&amp;X-Amz-SignedHeaders=host]
##   Date: 2022-09-14 17:37
##   Status: 200
##   Content-Type: application/vnd.openxmlformats-officedocument.spreadsheetml.sheet
##   Size: 180 kB
## &lt;ON DISK&gt;  /var/folders/r7/hs19zlvs2j90bd4drvgg_bq00000gn/T//Rtmpl4yHua/file94347f20a519.xlsx</code></pre>
<pre class="r"><code># Use read_excel to read it as dataframe
bike0 &lt;- read_excel(bike.temp,
                   sheet = &quot;Data&quot;,
                   range = cell_cols(&quot;A:B&quot;))

# change dates to get year, month, and week
bike &lt;- bike0 %&gt;% 
  clean_names() %&gt;% 
  rename (bikes_hired = number_of_bicycle_hires) %&gt;% 
  mutate (year = as.integer(year(day)),
          month = lubridate::month(day, label = TRUE),
          week = isoweek(day))

glimpse(bike)</code></pre>
<pre><code>## Rows: 4,416
## Columns: 5
## $ day         &lt;dttm&gt; 2010-07-30, 2010-07-31, 2010-08-01, 2010-08-02, 2010-08-0…
## $ bikes_hired &lt;dbl&gt; 6897, 5564, 4303, 6642, 7966, 7893, 8724, 9797, 6631, 7864…
## $ year        &lt;int&gt; 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010…
## $ month       &lt;ord&gt; Jul, Jul, Aug, Aug, Aug, Aug, Aug, Aug, Aug, Aug, Aug, Aug…
## $ week        &lt;dbl&gt; 30, 30, 30, 31, 31, 31, 31, 31, 31, 31, 32, 32, 32, 32, 32…</code></pre>
<p>First, we calculate the monthly change in Tfl bike rentals, calculated
as the difference between the actual monthly average and the historical
monthly average calculated between 2016-2019. We plot the data faceting
by year, using <code>geom_ribbon()</code> to visualize the positive/negative
deltas.</p>
<pre class="r"><code>#calculating expected number of rentals
compare &lt;- bike %&gt;%
  filter(year %in% c(2016:2019)) %&gt;% 
  group_by(month) %&gt;% 
  summarise(compare_avg = mean(bikes_hired))

#calculating monthly averages
avg &lt;- bike %&gt;% 
  filter(year %in% 2017:2022) %&gt;% 
  group_by(year, month) %&gt;% 
  summarise(actual_avg = mean(bikes_hired))
#joining datasets
left_join(avg, compare, by = &#39;month&#39;) %&gt;%
  #calculating differences
  mutate(difference = actual_avg - compare_avg, 
         pos_diff = ifelse(difference &gt; 0, actual_avg, 0),
         neg_diff = ifelse(difference &lt; 0, compare_avg, 0)) %&gt;%
  #plotting
  ggplot(aes(x = month)) +
  geom_line(aes(y = compare_avg, group = 1), color = &quot;blue&quot;, lwd = 1.5) +
  geom_line(aes(y = actual_avg, group = 1)) +
  geom_ribbon(aes(ymin = compare_avg, ymax = pmax(0, difference) + compare_avg, fill = &quot;red&quot;, alpha = 0.5, group = 1)) +
  geom_ribbon(aes(ymin = pmin(0, difference) + compare_avg, ymax = compare_avg, fill = &quot;green&quot;, alpha = 0.5, group = 1)) +
  facet_wrap(vars(year)) +
  labs(title = &quot;Monthly changes in Tfl bike rentals&quot;,
       subtitle = &quot;Change from monthly average shown in blue and calculated between 2016-2019&quot;,
       caption = &quot;Source: Tfl, London Data Store&quot;,
       x = NULL,
       y = &quot;Bike rentals&quot;) +
  theme(legend.position = &quot;none&quot;,
        axis.text.x = element_text(size = 6))</code></pre>
<p><img src="/blogs/homework2_working_file_files/figure-html/challenge1.1-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>We can see that Tfl bike rentals have been lower than in the 2016-2019
at the beginning of the pandemic, but quickly recovered and exceeded
historical data. Interestingly, there has been a significant uptake
starting in the second half of 2021, possibly due to changing
preferences regarding means of transport, with public transport losing
users to Tfl bikes.</p>
<p>Next, we plot a similar graph to visualize weekly changes in Tfl bike
rentals between actual data and the 2016-2019 average.</p>
<pre class="r"><code>#calculating expected number of rentals
compare &lt;- bike %&gt;%
  filter(year %in% c(2016:2019)) %&gt;% 
  group_by(week) %&gt;% 
  summarise(compare_avg = mean(bikes_hired))

#calculating weekly averages
avg &lt;- bike %&gt;% 
  filter(year %in% 2017:2022) %&gt;% 
  group_by(year, week) %&gt;% 
  summarise(actual_avg = mean(bikes_hired))

#deleting aberrant observations (average for future weeks in 2022)
avg &lt;- avg[-298,]

#joining dataframes
left_join(avg, compare, by = &#39;week&#39;) %&gt;%
  #calculating differences
  mutate(diff = (actual_avg - compare_avg)/compare_avg,
         pos_diff = ifelse(diff &gt; 0, diff, 0),
         neg_diff = ifelse(diff &lt; 0, diff, 0)) %&gt;%
  #plotting
  ggplot(aes(x = week, y = diff)) +
  scale_x_discrete(limits = c(13, 26, 39, 53)) +
  scale_y_continuous(labels = percent) +
  geom_rect(aes(xmin = 13, xmax = 26, ymin = -Inf, ymax = Inf), alpha = 0.3, fill = &quot;grey90&quot;) +
  geom_rect(aes(xmin = 39, xmax = 53, ymin = -Inf, ymax = Inf), alpha = 0.3, fill = &quot;grey90&quot;) +
  geom_line(aes(y = diff, group = 1), color = &#39;black&#39;, lwd = 0.8) +
  geom_ribbon(aes(ymin = 0, ymax = pmax(0, pos_diff)), fill = &#39;green&#39;, alpha = 0.3) +
  geom_ribbon(aes(ymin = pmin(0, neg_diff), ymax = 0), fill = &#39;red&#39;, alpha = 0.3) +
  geom_rug(aes(colour = diff), 
           sides = &#39;b&#39;, 
           length = unit(0.02, &quot;npc&quot;), 
           size = 1, 
           show.legend = FALSE) +
  binned_scale(aesthetics = &quot;colour&quot;,
               scale_name = &quot;stepsn&quot;,
               palette = function(x) c(&quot;red&quot;, &quot;green&quot;),
               breaks = c(0, 100)) +
  facet_wrap(vars(year)) +
  theme_minimal() +
  labs(title = &quot;Weekly changes in Tfl bike rentals&quot;,
       subtitle = &quot;% change from weekly averages calculated between 2016-2019&quot;,
       caption = &quot;Source: Tfl, London Data Store&quot;,
       x = &quot;Week&quot;,
       y = NULL)</code></pre>
<p><img src="/blogs/homework2_working_file_files/figure-html/challenge1.2-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>Again, one can easily notice the drops at the beginning of 2020 (start
of the pandemic) and in winter of 2021 (COVID wave), as well as the
sizable increase in Tfl rentals since the second half of 2021.</p>
<p>It should be noted that the mean has been used to calculate the expected
number of bike rentals for each month/week since the data follows a
normal distribution, as seen in the histogram below. Otherwise, it would
have been optimal to use the median instead, as it is a more robust
measure of central tendency.</p>
<pre class="r"><code>hist(bike$bikes_hired)</code></pre>
<p><img src="/blogs/homework2_working_file_files/figure-html/outliers-1.png" width="648" style="display: block; margin: auto;" /></p>
</div>
<div id="challenge-2-share-of-renewable-energy-production-in-the-world" class="section level1">
<h1>Challenge 2: Share of renewable energy production in the world</h1>
<p>This last section focuses on analysing the share of renewable energy
production around the world. We will be using datasets from the National
Bureau of Economic Research (NBER) and the World Bank.</p>
<p>The following is a description of the variables from the NBER dataset:</p>
<table>
<thead>
<tr class="header">
<th><strong>variable</strong></th>
<th><strong>class</strong></th>
<th><strong>description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>variable</td>
<td>character</td>
<td>Variable name</td>
</tr>
<tr class="even">
<td>label</td>
<td>character</td>
<td>Label for variable</td>
</tr>
<tr class="odd">
<td>iso3c</td>
<td>character</td>
<td>Country code</td>
</tr>
<tr class="even">
<td>year</td>
<td>double</td>
<td>Year</td>
</tr>
<tr class="odd">
<td>group</td>
<td>character</td>
<td>Group (consumption/production)</td>
</tr>
<tr class="even">
<td>category</td>
<td>character</td>
<td>Category</td>
</tr>
<tr class="odd">
<td>value</td>
<td>double</td>
<td>Value (related to label)</td>
</tr>
</tbody>
</table>
<pre class="r"><code>technology &lt;- readr::read_csv(&#39;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-07-19/technology.csv&#39;)

#get all technologies
labels &lt;- technology %&gt;% 
  distinct(variable, label)

# Get country names using &#39;countrycode&#39; package
technology &lt;- technology %&gt;% 
  filter(iso3c != &quot;XCD&quot;) %&gt;% 
  mutate(iso3c = recode(iso3c, &quot;ROM&quot; = &quot;ROU&quot;),
         country = countrycode(iso3c, origin = &quot;iso3c&quot;, destination = &quot;country.name&quot;),
         country = case_when(
           iso3c == &quot;ANT&quot; ~ &quot;Netherlands Antilles&quot;,
           iso3c == &quot;CSK&quot; ~ &quot;Czechoslovakia&quot;,
           iso3c == &quot;XKX&quot; ~ &quot;Kosovo&quot;,
           TRUE           ~ country))

#make smaller dataframe on energy
energy &lt;- technology %&gt;% 
  filter(category == &quot;Energy&quot;)

# download CO2 per capita from World Bank using {wbstats} package
# https://data.worldbank.org/indicator/EN.ATM.CO2E.PC
co2_percap &lt;- wb_data(country = &quot;countries_only&quot;, 
                      indicator = &quot;EN.ATM.CO2E.PC&quot;, 
                      start_date = 1970, 
                      end_date = 2022,
                      return_wide=FALSE) %&gt;% 
  filter(!is.na(value)) %&gt;% 
  #drop unwanted variables
  select(-c(unit, obs_status, footnote, last_updated))

# get a list of countries and their characteristics
# we just want to get the region a country is in and its income level
countries &lt;-  wb_cachelist$countries %&gt;% 
  select(iso3c,region,income_level)</code></pre>
<p>First, produce a graph with the countries with the highest and lowest %
contribution of renewables in energy production.</p>
<pre class="r"><code>#manipulating the dataset
data &lt;- energy %&gt;% 
  filter(year == 2019) %&gt;% 
  select(country, variable, value) %&gt;% 
  pivot_wider(names_from = &quot;variable&quot;, values_from = &quot;value&quot;) %&gt;% 
  arrange(country) %&gt;% 
  mutate(renew_share = (elec_solar + elec_hydro + elec_wind + elec_renew_other)/elecprod,
         renew_rounded = round(renew_share, digits = 4)) %&gt;% 
  drop_na(renew_rounded) %&gt;% 
  filter(renew_rounded &gt; 0) %&gt;% 
  arrange(desc(renew_rounded)) %&gt;% 
  select(country, renew_rounded)

#selecting top20 observations
max &lt;- data %&gt;%
  slice_max(n = 20, order_by = renew_rounded)

#plotting  
max_plot &lt;- ggplot(max, aes(x = renew_rounded, y = reorder(country, renew_rounded))) +
            geom_bar(stat = &#39;identity&#39;) +
            scale_x_continuous(labels = percent) +
            labs(x = NULL, y = NULL)

#selecting min20 observations
min &lt;- data %&gt;% 
  slice_min(n = 20, order_by = renew_rounded)

#plotting
min_plot &lt;- ggplot(min, aes(x = renew_rounded, y = reorder(country, renew_rounded))) +
            geom_bar(stat = &#39;identity&#39;) +
            scale_x_continuous(labels = percent) +
            labs(x = NULL, y = NULL)

library(patchwork)
full_plot &lt;- max_plot + min_plot 

full_plot + plot_annotation(
  title = &quot;Highest and lowest % in energy production&quot;,
  subtitle = &quot;2019 data&quot;,
  caption = &quot;NBER CHAT Database&quot;)</code></pre>
<p><img src="/blogs/homework2_working_file_files/figure-html/challenge2.1-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>We can see that countries with the highest share of renewables in their
energy mix are not necessarily the richest nations, and 8 states in that
group get 100% of their energy from renewable sources. Similarly, the
ones with the lowest % of renewables used to produce energy include some
of the wealthiest states in the world (Kuwait, Qatar), which is likely
due to their access to vast amounts of oil.</p>
<p>Second, we can produce an animation to explore the relationship between
CO2 per capita emissions and the deployment of renewables over time,
faceted by income group.</p>
<pre class="r"><code>#manipulating the data to facilitate time-series analysis
renewables &lt;- energy %&gt;% 
  select(iso3c, year, country, variable, value) %&gt;% 
  pivot_wider(names_from = &quot;variable&quot;, values_from = &quot;value&quot;) %&gt;% 
  arrange(country) %&gt;% 
  mutate(renew_share = (elec_solar + elec_hydro + elec_wind + elec_renew_other)/elecprod,
         renew_rounded = round(renew_share, digits = 4)) %&gt;% 
  drop_na(renew_rounded) %&gt;% 
  filter(renew_rounded &gt; 0) %&gt;% 
  select(iso3c, year, country, renew_rounded)

#deleting aberrant observations (share of renewables &gt; 100%)
renewables &lt;- renewables[-c(1:3), ]

#joining datasets to create a single dataframe
joined_first &lt;- left_join(renewables, co2_percap, by=c(&quot;iso3c&quot; = &quot;iso3c&quot;, &quot;year&quot; = &quot;date&quot;))
full_data &lt;- left_join(joined_first, countries, by = &quot;iso3c&quot;)

#filtering the dataset
for_plots &lt;- full_data %&gt;% 
  mutate(year = as.integer(year)) %&gt;% 
  select(year, country.x, renew_rounded, value, income_level) %&gt;%
  drop_na(income_level, value) %&gt;% 
  filter(year %in% 1990:2020)

#plotting
plot &lt;- for_plots %&gt;% 
  ggplot(aes(x = renew_rounded, y = value, color = income_level)) +
  geom_point() +
  ylim(0, 50) +
  facet_wrap(vars(income_level)) +
  labs(title = &#39;Year: {frame_time}&#39;, 
       x = &#39;% renewables&#39;, 
       y = &#39;CO2 per cap&#39;) +
  transition_time(year) +
  ease_aes(&#39;linear&#39;) +
  theme(legend.position = &quot;none&quot;) +
  scale_x_continuous(labels = percent)

for_plots</code></pre>
<pre><code>## # A tibble: 3,851 × 5
##     year country.x   renew_rounded  value income_level
##    &lt;int&gt; &lt;chr&gt;               &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;       
##  1  2003 Afghanistan         0.671 0.0515 Low income  
##  2  2004 Afghanistan         0.632 0.0417 Low income  
##  3  2005 Afghanistan         0.632 0.0604 Low income  
##  4  2006 Afghanistan         0.761 0.0666 Low income  
##  5  2007 Afghanistan         0.791 0.0653 Low income  
##  6  2008 Afghanistan         0.744 0.128  Low income  
##  7  2009 Afghanistan         0.827 0.172  Low income  
##  8  2010 Afghanistan         0.802 0.244  Low income  
##  9  2011 Afghanistan         0.703 0.297  Low income  
## 10  2012 Afghanistan         0.809 0.259  Low income  
## # … with 3,841 more rows</code></pre>
<pre class="r"><code>plot</code></pre>
<pre><code>## NULL</code></pre>
<p>The animation shows that as the % of energy generated by renewables goes
up, CO2 per capita emissions do not seem to go down. This would be
signified by dots moving diagonally from the upper-left to the
lower-right corner of the plot. However, no such movement is detected.
In fact, we can observe that quite a few countries move horizontally to
the right, which means that their CO2 per capita emissions stay constant
as the share of renewables in their energy mix increases.</p>
</div>
<div id="details" class="section level1">
<h1>Details</h1>
<ul>
<li>Who did you collaborate with: Samarth Sharma, Vivian van Oosten,
Anastasia Fu, Jaelyn Shi, Andrew Robak, Shivant Maharaj</li>
<li>Approximately how much time did you spend on this problem set: 10h</li>
<li>What, if anything, gave you the most trouble: shadowing the two
quarters in challenge 1</li>
</ul>
</div>
